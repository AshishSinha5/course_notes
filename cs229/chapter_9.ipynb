{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization and Model Selection\n",
    "\n",
    "Regularization is a technique in machine learning to control model complexity and prevent overfitting. Typically involves adding an additional term, called a regularizer and denoted by $R(\\theta)$, to the training loss/cost function.\n",
    "$$\n",
    "J_{\\lambda}(\\theta) = J(\\theta) + \\lambda R(\\theta)\n",
    "$$\n",
    "- $J_{\\lambda}$ - regularized loss\n",
    "- $\\lambda \\geq 0$ - regularization parameter\n",
    "\n",
    "Here, $R(\\theta)$ is typically some measure of complexity of model $\\theta$, $\\therefore$ by using a regularized cost function we aim to find the model that fits both the data (minimize $J(\\theta)$) and has smaller complexity i.e. $R(\\theta)$.\n",
    "\n",
    "The regularization parameter acts as a tradeoff between the two objectives - \n",
    "\n",
    "|$\\lambda$| Implication|\n",
    "|-------|--|\n",
    "|$\\lambda = 0$| Unregularized loss function i.e. minimizing only the $J(\\theta)$.|\n",
    "|$\\lambda \\approx 0$| Again effectively minimizing the loss function $J(\\theta)$ with regularization term acting as a tie breaker when multiple solutions with similar loss values exists.|\n",
    "|$\\lambda >> 0$|The original loss is not effective anymore leading to high bias of the model.|\n",
    "\n",
    "Types of Regularization - \n",
    "- L2 regularization - $R(\\theta) = \\frac{1}{2}||\\theta||_2^2$\n",
    "- L1 regularization - $R(\\theta) = \\frac{1}{2}||\\theta||_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
