{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Learning Algorithms\n",
    "\n",
    "- Algorithms that learn $p(y|x)$ directly from the training data are called the **descriminative learning algorithms**.\n",
    "- Algorithms that model $p(x|y)$ and $p(y)$ from the training examples are called the **generative models**.\n",
    "e.g. For a binary classification problem, we can learn $p(x|y=0)$ and $p(x|y=1)$  i.e. given the class labels $y$ how does the distribution of features look like. We'll also model the class distribution $p(y)$ and find the posterior distribution $p(y|x)$ for any new training example $x$ - \n",
    "$$\n",
    "p(y|x) = \\frac{p(x|y)p(y)}{p(x|y=0)p(y=0) + p(x|y=1)p(y=1)}\n",
    "$$ \n",
    "To make the predictions - \n",
    "$$\\begin{align*}\n",
    "\\hat{y} &= argmax_yp(y|x) = argmax_y\\frac{p(x|y)p(y)}{p(x)} \\\\\n",
    "&= argmax_yp(x|y)p(y)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Discriminant Analysis (GDA)\n",
    "When $p(x|y)$ is distributed as multivariate Gaussian Distribution. \n",
    "\n",
    "### Multivariate Normal Distribution - \n",
    "Probability distribution function is given by - \n",
    "$$\n",
    "p(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}exp(-\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu))\n",
    "$$\n",
    "Where -\n",
    "- $\\mu \\in \\bf{R}^d$ - mean vector \n",
    "- $\\Sigma \\in \\bf{R}^{d \\times d}$ - covariance matrix, symmetric and positive definite\n",
    "- $|\\Sigma|$ - determinant of the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
